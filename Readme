#  Titanic Survival Prediction: End-to-End PyTorch Pipeline

![Python](https://img.shields.io/badge/python-3.9+-blue.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=flat&logo=pytorch&logoColor=white)
![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B?style=flat&logo=streamlit&logoColor=white)

An end-to-end Deep Learning pipeline for the Titanic Kaggle competition, featuring a PyTorch neural network and an interactive Streamlit dashboard.

##  Features
* **Full Pipeline:** From raw Kaggle data to a deployed model.
* **Deep Learning:** Custom Neural Network built with PyTorch.
* **Interactive UI:** Live inference using Streamlit.
* **EDA:** Detailed analysis in Jupyter Notebook.

## Dashboard Preview

![Dashboard Screenshot](path/to/your/screenshot.png)

## ğŸ—ï¸ Project Structure

Project Structure


â”œâ”€â”€ .env                  # Your private Kaggle credentials (not tracked by Git)
â”œâ”€â”€ .env.example          # Template for environment variables
â”œâ”€â”€ .gitignore            # Files to ignore (including .env and model artifacts)
â”œâ”€â”€ ds_app.py             # Streamlit Inference UI
â”œâ”€â”€ train.py              # Standalone training script
â”œâ”€â”€ model_utils.py        # Utility functions: Data cleaning, NN architecture
â”œâ”€â”€ Data_Science_Home_Assignment_Segev_Ohana.ipynb     # Jupyter Notebook for Exploratory Data Analysis
â”œâ”€â”€ requirements.txt      # Project dependencies
â”œâ”€â”€ run_app_script.bat    # Batch file to run the full pipeline
â””â”€â”€ README.md             # Project documentation


